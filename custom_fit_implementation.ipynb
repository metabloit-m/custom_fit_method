{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch #0\n",
      "sparse_categorical_accuracy : 0.0000\n",
      "loss : 0.2904\n",
      "Results at the end of epoch #1\n",
      "sparse_categorical_accuracy : 0.0005\n",
      "loss : 0.1652\n",
      "Results at the end of epoch #2\n",
      "sparse_categorical_accuracy : 0.0012\n",
      "loss : 0.1391\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28*28,))\n",
    "    features = layers.Dense(512, activation='relu')(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    output = layers.Dense(10, activation='softmax')(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "@tf.function #Compile tensorflow code to computational graph for global optimization. It enables fast execution\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss_val = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss_val, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs={}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(predictions, targets)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss_val)\n",
    "    logs['loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28*28)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28*28)).astype('float32') / 255\n",
    "\n",
    "train_images, val_train_images = train_images[10000:], train_images[:10000]\n",
    "train_labels, val_train_labels = train_labels[10000:], train_labels[:10000]\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for input_batch, input_target in training_dataset:\n",
    "        logs = train_step(input_batch, input_target)\n",
    "    print(f'Results at the end of epoch #{epoch}')\n",
    "    for key, value in logs.items():\n",
    "        print(f'{key} : {value:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}